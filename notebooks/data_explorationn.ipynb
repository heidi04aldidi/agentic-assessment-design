{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6654939f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19f32d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/amitianeesh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import html\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download(\"stopwords\")  # run only once\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9006de5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "QUESTIONS_PATH = \"../data/raw/Questions.csv\"\n",
    "ANSWERS_PATH = \"../data/raw/Answers.csv\"\n",
    "TAGS_PATH = \"../data/raw/Tags.csv\"\n",
    "\n",
    "QUESTIONS_OUTPUT_PATH = \"../data/processed/questions_clean.csv\"\n",
    "ANSWERS_OUTPUT_PATH = \"../data/processed/answers_clean.csv\"\n",
    "\n",
    "CHUNK_SIZE = 50000  # rows processed at a time(large so chunckwise)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736c9622",
   "metadata": {},
   "source": [
    "counting questions/answers/tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e48a58d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1264216"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "question_count = sum(\n",
    "    len(chunk)\n",
    "    for chunk in pd.read_csv(QUESTIONS_PATH, encoding=\"latin1\", chunksize=100000)\n",
    ")\n",
    "\n",
    "question_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe0dfb26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2014516"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_count = sum(\n",
    "    len(chunk)\n",
    "    for chunk in pd.read_csv(ANSWERS_PATH, encoding=\"latin1\", chunksize=100000)\n",
    ")\n",
    "\n",
    "answer_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72e13e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3750994"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_count = sum(\n",
    "    len(chunk)\n",
    "    for chunk in pd.read_csv(TAGS_PATH, encoding=\"latin1\", chunksize=100000)\n",
    ")\n",
    "\n",
    "tag_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ad31fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TYpe</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Questions</td>\n",
       "      <td>1264216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Answers</td>\n",
       "      <td>2014516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tags</td>\n",
       "      <td>3750994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TYpe    Count\n",
       "0  Questions  1264216\n",
       "1    Answers  2014516\n",
       "2       Tags  3750994"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_summary = pd.DataFrame({\n",
    "    \"TYpe\": [\"Questions\", \"Answers\", \"Tags\"],\n",
    "    \"Count\": [question_count, answer_count, tag_count]\n",
    "})\n",
    "\n",
    "dataset_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8d0ee2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>ClosedDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>26</td>\n",
       "      <td>2008-08-01T13:57:07Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>SQLStatement.execute() - multiple queries in o...</td>\n",
       "      <td>&lt;p&gt;I've written a database generation script i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  OwnerUserId          CreationDate ClosedDate  Score  \\\n",
       "0  80           26  2008-08-01T13:57:07Z        NaN     26   \n",
       "\n",
       "                                               Title  \\\n",
       "0  SQLStatement.execute() - multiple queries in o...   \n",
       "\n",
       "                                                Body  \n",
       "0  <p>I've written a database generation script i...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df_ques= pd.read_csv(\n",
    "    QUESTIONS_PATH,\n",
    "    encoding=\"latin1\",\n",
    "    nrows=5\n",
    ")\n",
    "\n",
    "# sample_df_ques.head()\n",
    "sample_df_ques.head(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72136158",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "697ef3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df_ques= pd.read_csv(\n",
    "    QUESTIONS_PATH,\n",
    "    encoding=\"latin1\",\n",
    "    nrows=5\n",
    ")\n",
    "\n",
    "sample_df_ques.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cf70219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import XMLParsedAsHTMLWarning\n",
    "import warnings\n",
    "\n",
    "# Suppress XML warning once\n",
    "warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4db98f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_pipeline(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "\n",
    "    # Decode HTML entities (e.g., &lt; â†’ <)\n",
    "    text = html.unescape(text)\n",
    "    try:\n",
    "        # Remove HTML/XML tags\n",
    "        text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove non-alphabetic characters\n",
    "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
    "\n",
    "    # Normalize multiple spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "    # Tokenize\n",
    "    tokens = text.split()\n",
    "\n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Join back\n",
    "    text = \" \".join(tokens)\n",
    "\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66108dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW TEXT:\n",
      " SQLStatement.execute() - multiple queries in one statement <p>I've written a database generation script in <a href=\"http://en.wikipedia.org/wiki/SQL\">SQL</a> and want to execute it in my <a href=\"http://en.wikipedia.org/wiki/Adobe_Integrated_Runtime\">Adobe AIR</a> application:</p>\n",
      "\n",
      "<pre><code>Create Table tRole (\n",
      "      roleID integer Primary Key\n",
      "      ,roleName varchar(40)\n",
      ");\n",
      "Create Table tFile (\n",
      "    fileID integer Primary Key\n",
      "    ,fileName varchar(50)\n",
      "    ,fileDescription varchar(500)\n",
      "    ,thum\n",
      "\n",
      "CLEAN TEXT:\n",
      " sqlstatement execute multiple queries one statement written database generation script sql want execute adobe air application create table trole roleid integer primary key rolename varchar create table tfile fileid integer primary key filename varchar filedescription varchar thumbnailid integer fileformatid integer categoryid integer isfavorite boolean dateadded date globalaccesscount integer lastaccesstime date downloadcomplete boolean isnew boolean isspotlight boolean duration varchar create t\n"
     ]
    }
   ],
   "source": [
    "# Test Cleaning on Small Subset\n",
    "test_df = pd.read_csv(\n",
    "    QUESTIONS_PATH,\n",
    "    encoding=\"latin1\",\n",
    "    nrows=10000\n",
    ")\n",
    "\n",
    "test_df[\"raw_text\"] = (\n",
    "    test_df[\"Title\"].fillna(\"\") + \" \" +\n",
    "    test_df[\"Body\"].fillna(\"\")\n",
    ")\n",
    "\n",
    "test_df[\"clean_text\"] = test_df[\"raw_text\"].apply(clean_text_pipeline)\n",
    "\n",
    "sample = test_df[[\"raw_text\", \"clean_text\"]].iloc[0]\n",
    "\n",
    "print(\"RAW TEXT:\\n\", sample[\"raw_text\"][:500])\n",
    "print(\"\\nCLEAN TEXT:\\n\", sample[\"clean_text\"][:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3dd6b229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Full preprocessing complete.\n"
     ]
    }
   ],
   "source": [
    "# Full Dataset Cleaning (Chunk Processing)\n",
    "first_chunk = True\n",
    "\n",
    "for chunk in pd.read_csv(\n",
    "    QUESTIONS_PATH,\n",
    "    encoding=\"latin1\",\n",
    "    chunksize=CHUNK_SIZE\n",
    "):\n",
    "\n",
    "    # Combine title and body\n",
    "    chunk[\"raw_text\"] = (\n",
    "        chunk[\"Title\"].fillna(\"\") + \" \" +\n",
    "        chunk[\"Body\"].fillna(\"\")\n",
    "    )\n",
    "\n",
    "    # Apply cleaning pipeline\n",
    "    chunk[\"clean_text\"] = chunk[\"raw_text\"].apply(clean_text_pipeline)\n",
    "\n",
    "    # Keep only relevant columns\n",
    "    processed_chunk = chunk[[\"Id\", \"Score\", \"clean_text\"]]\n",
    "\n",
    "    # Write incrementally\n",
    "    processed_chunk.to_csv(\n",
    "        QUESTIONS_OUTPUT_PATH,\n",
    "        mode=\"w\" if first_chunk else \"a\",\n",
    "        header=first_chunk,\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    first_chunk = False\n",
    "\n",
    "print(\" Full preprocessing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "187227f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(os.path.dirname(QUESTIONS_OUTPUT_PATH), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d137241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Score</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>26</td>\n",
       "      <td>sqlstatement execute multiple queries one stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>144</td>\n",
       "      <td>good branching merging tutorials tortoisesvn r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120</td>\n",
       "      <td>21</td>\n",
       "      <td>asp net site maps anyone got experience creati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>180</td>\n",
       "      <td>53</td>\n",
       "      <td>function creating color wheels something pseud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>260</td>\n",
       "      <td>49</td>\n",
       "      <td>adding scripting functionality net application...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  Score                                         clean_text\n",
       "0   80     26  sqlstatement execute multiple queries one stat...\n",
       "1   90    144  good branching merging tutorials tortoisesvn r...\n",
       "2  120     21  asp net site maps anyone got experience creati...\n",
       "3  180     53  function creating color wheels something pseud...\n",
       "4  260     49  adding scripting functionality net application..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify\n",
    "clean_df_sample = pd.read_csv(QUESTIONS_OUTPUT_PATH, nrows=5)\n",
    "\n",
    "clean_df_sample.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcda9854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rows: 1264216\n",
      "Cleaned rows: 1264216\n"
     ]
    }
   ],
   "source": [
    "original_count = sum(\n",
    "    len(chunk)\n",
    "    for chunk in pd.read_csv(QUESTIONS_PATH, encoding=\"latin1\", chunksize=100000)\n",
    ")\n",
    "\n",
    "clean_count = sum(\n",
    "    len(chunk)\n",
    "    for chunk in pd.read_csv(QUESTIONS_OUTPUT_PATH, chunksize=100000)\n",
    ")\n",
    "\n",
    "print(\"Original rows:\", original_count)\n",
    "print(\"Cleaned rows:\", clean_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7463a7d4",
   "metadata": {},
   "source": [
    "answers cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4403828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>ClosedDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>26</td>\n",
       "      <td>2008-08-01T13:57:07Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>SQLStatement.execute() - multiple queries in o...</td>\n",
       "      <td>&lt;p&gt;I've written a database generation script i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>58</td>\n",
       "      <td>2008-08-01T14:41:24Z</td>\n",
       "      <td>2012-12-26T03:45:49Z</td>\n",
       "      <td>144</td>\n",
       "      <td>Good branching and merging tutorials for Torto...</td>\n",
       "      <td>&lt;p&gt;Are there any really good tutorials explain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120</td>\n",
       "      <td>83</td>\n",
       "      <td>2008-08-01T15:50:08Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>ASP.NET Site Maps</td>\n",
       "      <td>&lt;p&gt;Has anyone got experience creating &lt;strong&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>180</td>\n",
       "      <td>2089740</td>\n",
       "      <td>2008-08-01T18:42:19Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>Function for creating color wheels</td>\n",
       "      <td>&lt;p&gt;This is something I've pseudo-solved many t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>260</td>\n",
       "      <td>91</td>\n",
       "      <td>2008-08-01T23:22:08Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49</td>\n",
       "      <td>Adding scripting functionality to .NET applica...</td>\n",
       "      <td>&lt;p&gt;I have a little game written in C#. It uses...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  OwnerUserId          CreationDate            ClosedDate  Score  \\\n",
       "0   80           26  2008-08-01T13:57:07Z                   NaN     26   \n",
       "1   90           58  2008-08-01T14:41:24Z  2012-12-26T03:45:49Z    144   \n",
       "2  120           83  2008-08-01T15:50:08Z                   NaN     21   \n",
       "3  180      2089740  2008-08-01T18:42:19Z                   NaN     53   \n",
       "4  260           91  2008-08-01T23:22:08Z                   NaN     49   \n",
       "\n",
       "                                               Title  \\\n",
       "0  SQLStatement.execute() - multiple queries in o...   \n",
       "1  Good branching and merging tutorials for Torto...   \n",
       "2                                  ASP.NET Site Maps   \n",
       "3                 Function for creating color wheels   \n",
       "4  Adding scripting functionality to .NET applica...   \n",
       "\n",
       "                                                Body  \n",
       "0  <p>I've written a database generation script i...  \n",
       "1  <p>Are there any really good tutorials explain...  \n",
       "2  <p>Has anyone got experience creating <strong>...  \n",
       "3  <p>This is something I've pseudo-solved many t...  \n",
       "4  <p>I have a little game written in C#. It uses...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df_ans= pd.read_csv(\n",
    "    ANSWERS_PATH,\n",
    "    encoding=\"latin1\",\n",
    "    nrows=5\n",
    ")\n",
    "\n",
    "# sample_df_ans.head()\n",
    "sample_df_ques.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd008de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW TEXT:\n",
      " <p><a href=\"http://svnbook.red-bean.com/\">Version Control with Subversion</a></p>\n",
      "\n",
      "<p>A very good resource for source control in general. Not really TortoiseSVN specific, though.</p>\n",
      "\n",
      "CLEAN TEXT:\n",
      " version control subversion good resource source control general really tortoisesvn specific though\n"
     ]
    }
   ],
   "source": [
    "# Test Cleaning on Small Subset of ans\n",
    "test_df_ans = pd.read_csv(\n",
    "    ANSWERS_PATH,\n",
    "    encoding=\"latin1\",\n",
    "    nrows=10000\n",
    ")\n",
    "\n",
    "test_df_ans[\"raw_text\"] = (\n",
    "    test_df_ans[\"Body\"].fillna(\"\")\n",
    ")\n",
    "\n",
    "test_df_ans[\"clean_text\"] = test_df_ans[\"raw_text\"].apply(clean_text_pipeline)\n",
    "\n",
    "sample = test_df_ans[[\"raw_text\", \"clean_text\"]].iloc[0]\n",
    "\n",
    "print(\"RAW TEXT:\\n\", sample[\"raw_text\"][:500])\n",
    "print(\"\\nCLEAN TEXT:\\n\", sample[\"clean_text\"][:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7a18138",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     11\u001b[39m chunk[\u001b[33m\"\u001b[39m\u001b[33mraw_text\u001b[39m\u001b[33m\"\u001b[39m] = (\n\u001b[32m     12\u001b[39m     chunk[\u001b[33m\"\u001b[39m\u001b[33mBody\u001b[39m\u001b[33m\"\u001b[39m].fillna(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m )\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Apply cleaning pipeline\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m chunk[\u001b[33m\"\u001b[39m\u001b[33mclean_text\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mchunk\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mraw_text\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_text_pipeline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Keep only relevant columns\u001b[39;00m\n\u001b[32m     19\u001b[39m processed_chunk = chunk[[\u001b[33m\"\u001b[39m\u001b[33mId\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mScore\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mclean_text\u001b[39m\u001b[33m\"\u001b[39m]]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/agentic-assessment-design/venv/lib/python3.14/site-packages/pandas/core/series.py:4943\u001b[39m, in \u001b[36mSeries.apply\u001b[39m\u001b[34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[39m\n\u001b[32m   4808\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\n\u001b[32m   4809\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4810\u001b[39m     func: AggFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4815\u001b[39m     **kwargs,\n\u001b[32m   4816\u001b[39m ) -> DataFrame | Series:\n\u001b[32m   4817\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4818\u001b[39m \u001b[33;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[32m   4819\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4934\u001b[39m \u001b[33;03m    dtype: float64\u001b[39;00m\n\u001b[32m   4935\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   4936\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4937\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4938\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4939\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4940\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4941\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4942\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m4943\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/agentic-assessment-design/venv/lib/python3.14/site-packages/pandas/core/apply.py:1422\u001b[39m, in \u001b[36mSeriesApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_compat()\n\u001b[32m   1421\u001b[39m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/agentic-assessment-design/venv/lib/python3.14/site-packages/pandas/core/apply.py:1502\u001b[39m, in \u001b[36mSeriesApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1496\u001b[39m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[32m   1497\u001b[39m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[32m   1498\u001b[39m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[32m   1499\u001b[39m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[32m   1500\u001b[39m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[32m   1501\u001b[39m action = \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj.dtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1502\u001b[39m mapped = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1503\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1506\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[32m0\u001b[39m], ABCSeries):\n\u001b[32m   1507\u001b[39m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[32m   1508\u001b[39m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index=obj.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/agentic-assessment-design/venv/lib/python3.14/site-packages/pandas/core/base.py:925\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    923\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/agentic-assessment-design/venv/lib/python3.14/site-packages/pandas/core/algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:2999\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mclean_text_pipeline\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m      6\u001b[39m text = html.unescape(text)\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# Remove HTML/XML tags\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     text = \u001b[43mBeautifulSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhtml.parser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.get_text()\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/agentic-assessment-design/venv/lib/python3.14/site-packages/bs4/__init__.py:448\u001b[39m, in \u001b[36mBeautifulSoup.__init__\u001b[39m\u001b[34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[39m\n\u001b[32m    444\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(markup, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(markup, \u001b[33m\"\u001b[39m\u001b[33m__len__\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    445\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    446\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIncoming markup is of an invalid type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmarkup\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m. Markup must be a string, a bytestring, or an open filehandle.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    447\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmarkup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSized\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(markup) <= \u001b[32m256\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[32m    449\u001b[39m     (\u001b[38;5;28misinstance\u001b[39m(markup, \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m<\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m markup \u001b[38;5;129;01mand\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m markup)\n\u001b[32m    450\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(markup, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m<\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m markup \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m markup)\n\u001b[32m    451\u001b[39m ):\n\u001b[32m    452\u001b[39m     \u001b[38;5;66;03m# Issue warnings for a couple beginner problems\u001b[39;00m\n\u001b[32m    453\u001b[39m     \u001b[38;5;66;03m# involving passing non-markup to Beautiful Soup.\u001b[39;00m\n\u001b[32m    454\u001b[39m     \u001b[38;5;66;03m# Beautiful Soup will still parse the input as markup,\u001b[39;00m\n\u001b[32m    455\u001b[39m     \u001b[38;5;66;03m# since that is sometimes the intended behavior.\u001b[39;00m\n\u001b[32m    456\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._markup_is_url(markup):\n\u001b[32m    457\u001b[39m         \u001b[38;5;28mself\u001b[39m._markup_resembles_filename(markup)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.14/3.14.3_1/Frameworks/Python.framework/Versions/3.14/lib/python3.14/typing.py:1292\u001b[39m, in \u001b[36m_BaseGenericAlias.__instancecheck__\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m   1289\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1290\u001b[39m         \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.__origin__, attr, val)\n\u001b[32m-> \u001b[39m\u001b[32m1292\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__instancecheck__\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj):\n\u001b[32m   1293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__subclasscheck__\u001b[39m(\u001b[38;5;28mtype\u001b[39m(obj))\n\u001b[32m   1295\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__subclasscheck__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mcls\u001b[39m):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Full Dataset Cleaning (Chunk Processing)\n",
    "first_chunk = True\n",
    "\n",
    "for chunk in pd.read_csv(\n",
    "    ANSWERS_PATH,\n",
    "    encoding=\"latin1\",\n",
    "    chunksize=CHUNK_SIZE\n",
    "):\n",
    "\n",
    "    # Combine title and body\n",
    "    chunk[\"raw_text\"] = (\n",
    "        chunk[\"Body\"].fillna(\"\")\n",
    "    )\n",
    "\n",
    "    # Apply cleaning pipeline\n",
    "    chunk[\"clean_text\"] = chunk[\"raw_text\"].apply(clean_text_pipeline)\n",
    "\n",
    "    # Keep only relevant columns\n",
    "    processed_chunk = chunk[[\"Id\", \"Score\", \"clean_text\"]]\n",
    "\n",
    "    # Write incrementally\n",
    "    processed_chunk.to_csv(\n",
    "        ANSWERS_OUTPUT_PATH,\n",
    "        mode=\"w\" if first_chunk else \"a\",\n",
    "        header=first_chunk,\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    first_chunk = False\n",
    "\n",
    "print(\" Full preprocessing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7728fcc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Score</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>26</td>\n",
       "      <td>sqlstatement execute multiple queries one stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90</td>\n",
       "      <td>144</td>\n",
       "      <td>good branching merging tutorials tortoisesvn r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120</td>\n",
       "      <td>21</td>\n",
       "      <td>asp net site maps anyone got experience creati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>180</td>\n",
       "      <td>53</td>\n",
       "      <td>function creating color wheels something pseud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>260</td>\n",
       "      <td>49</td>\n",
       "      <td>adding scripting functionality net application...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  Score                                         clean_text\n",
       "0   80     26  sqlstatement execute multiple queries one stat...\n",
       "1   90    144  good branching merging tutorials tortoisesvn r...\n",
       "2  120     21  asp net site maps anyone got experience creati...\n",
       "3  180     53  function creating color wheels something pseud...\n",
       "4  260     49  adding scripting functionality net application..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify\n",
    "clean_df_sample = pd.read_csv(QUESTIONS_OUTPUT_PATH, nrows=5)\n",
    "\n",
    "clean_df_sample.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abd4c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF VECTORIZATION\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import save_npz\n",
    "\n",
    "# Load cleaned questions\n",
    "clean_questions = pd.read_csv(\"../data/processed/questions_clean.csv\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "    min_df=5,\n",
    "    max_df=0.8,\n",
    "    ngram_range=(1,2),\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "tfidf_questions = vectorizer.fit_transform(clean_questions[\"clean_text\"].fillna(\"\"))\n",
    "\n",
    "import joblib\n",
    "joblib.dump(vectorizer, \"../data/processed/tfidf_vectorizer.pkl\")\n",
    "\n",
    "print(\"Questions TF-IDF Shape:\", tfidf_questions.shape)\n",
    "\n",
    "# Save sparse matrix\n",
    "save_npz(\"../data/processed/questions_tfidf.npz\", tfidf_questions)\n",
    "\n",
    "print(\"Questions TF-IDF saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdce94bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answers TF-IDF Shape: (2014516, 10000)\n",
      "Answers TF-IDF saved successfully.\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import load_npz\n",
    "\n",
    "# Load cleaned answers\n",
    "clean_answers = pd.read_csv(\"../data/processed/answers_clean.csv\")\n",
    "\n",
    "# Load saved vectorizer\n",
    "vectorizer = joblib.load(\"../data/processed/tfidf_vectorizer.pkl\")\n",
    "\n",
    "# Transform answers (DO NOT FIT AGAIN)\n",
    "tfidf_answers = vectorizer.transform(clean_answers[\"clean_text\"].fillna(\"\"))\n",
    "\n",
    "print(\"Answers TF-IDF Shape:\", tfidf_answers.shape)\n",
    "\n",
    "# Save sparse matrix\n",
    "save_npz(\"../data/processed/answers_tfidf.npz\", tfidf_answers)\n",
    "\n",
    "print(\"Answers TF-IDF saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bf256a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_questions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mclean_questions\u001b[49m.head()\n",
      "\u001b[31mNameError\u001b[39m: name 'clean_questions' is not defined"
     ]
    }
   ],
   "source": [
    "# Scalling the score and made it till out of 100\n",
    "clean_answers['score_out_of_100'] = (\n",
    "    clean_answers['Score'] /\n",
    "    clean_answers.groupby('id')['Score'].transform('max')\n",
    ") * 100\n",
    "\n",
    "# calculated the averge by group of that that particular question id.\n",
    "clean_answers['average_score'] = (clean_answers.groupby('id')['score_out_of_100'].transform('mean'))\n",
    "\n",
    "# added a new column of difficulty label and hardcoded the bins such that if average score defines the difficulty.\n",
    "def assign_difficulty(score):\n",
    "    if score >= 70:\n",
    "        return \"Easy\"\n",
    "    elif score >= 40:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Hard\"\n",
    "\n",
    "clean_answers['difficulty'] = (\n",
    "    clean_answers['average_score']\n",
    "    .apply(assign_difficulty)\n",
    ")\n",
    "\n",
    "clean_answers.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
